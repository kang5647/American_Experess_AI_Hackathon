{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79df56a6-7950-48a3-a176-9e35a7ce9e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import dask.dataframe as dd\n",
    "from IPython.display import display, HTML\n",
    "import pandas as pd\n",
    "import cudf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "944ad0ed-fef2-42ae-a6cc-f8fbc62c54b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml.linear_model import LinearRegression, LogisticRegression\n",
    "import cudf\n",
    "import numpy as np\n",
    "import gc\n",
    "import cupy as cp\n",
    "import joblib  # For saving the model\n",
    "\n",
    "import cudf\n",
    "from cuml.linear_model import LinearRegression, LogisticRegression\n",
    "import joblib\n",
    "\n",
    "def regression_impute_column(df, target_column, features, is_categorical=False, model_save_path=None):\n",
    "    \"\"\"\n",
    "    Impute missing values in a specific column using regression models based on a specific set of features and save the model.\n",
    "    \n",
    "    Parameters:\n",
    "    df (cudf.DataFrame): The input dataframe.\n",
    "    target_column (str): The name of the column to impute.\n",
    "    features (list): List of column names to be used as features for the model.\n",
    "    is_categorical (bool): Flag to indicate if the target column is categorical.\n",
    "    model_save_path (str): Path to save the trained model.\n",
    "    \"\"\"\n",
    "    print(\"Preparing data...\")\n",
    "\n",
    "    # Ensure the target column is not in the features list\n",
    "    features = [col for col in features if col != target_column]\n",
    "    \n",
    "    # Split the dataframe into rows with and without missing values in the target column\n",
    "    df_with_values = df[df[target_column].notnull()]\n",
    "    df_missing_values = df[df[target_column].isnull()]\n",
    "\n",
    "    if len(df_missing_values) == 0:\n",
    "        print(\"No imputation needed.\")\n",
    "        return df  # No imputation needed if no missing values\n",
    "\n",
    "    # Select only the specified features for training and imputation\n",
    "    X_train = df_with_values[features].fillna(0)\n",
    "    y_train = df_with_values[target_column]\n",
    "    X_missing = df_missing_values[features].fillna(0)\n",
    "    \n",
    "    # Choose the model based on the data type\n",
    "    if is_categorical:\n",
    "        model = LogisticRegression()\n",
    "    else:\n",
    "        model = LinearRegression()\n",
    "        \n",
    "    print(\"Start imputing...\")\n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Save the model if a path is provided\n",
    "    if model_save_path:\n",
    "        joblib.dump(model, model_save_path)\n",
    "        print(f\"Model saved to {model_save_path}\")\n",
    "    \n",
    "    # Predict the missing values\n",
    "    predicted_values = model.predict(X_missing)\n",
    "    \n",
    "    # Update the DataFrame with imputed values\n",
    "    df.loc[df[target_column].isnull(), target_column] = predicted_values\n",
    "    del X_train, y_train, X_missing, df_with_values, df_missing_values\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60856cdb-9f32-4b00-b4eb-8cc1695fcbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_impute_and_save(df, features, start_index=0, batch_size=9, base_filename='imputed_df'):\n",
    "    \"\"\"\n",
    "    Perform imputation on batches of columns and save intermediate results.\n",
    "    \n",
    "    Args:\n",
    "    df (cudf.DataFrame): The DataFrame to impute.\n",
    "    numerical_categories (list): List of columns to impute.\n",
    "    start_index (int): Column index to start imputation.\n",
    "    batch_size (int): Number of columns to impute per batch.\n",
    "    base_filename (str): Base name for saving intermediate Parquet files.\n",
    "    \n",
    "    Returns:\n",
    "    int: Index of the last column processed.\n",
    "    \"\"\"\n",
    "    for i, target in enumerate(features[start_index:], start=start_index):\n",
    "        is_categorical = target == \"merchant_profile_01\"\n",
    "        \n",
    "        # Define the path to save the model\n",
    "        model_save_path = f'impute_models/{target}_model.pkl'\n",
    "        \n",
    "        # Pass the model_save_path to the regression_impute_column function\n",
    "        df = regression_impute_column(df, target, features, is_categorical=is_categorical, model_save_path=model_save_path)\n",
    "        \n",
    "        print(f'Successfully imputed values for {\"categorical\" if is_categorical else \"numerical\"} column: {target}')\n",
    "        \n",
    "        if (i + 1) % batch_size == 0:\n",
    "            # Save intermediate results\n",
    "            save_path = f'impute_data/{base_filename}_{i + 1}.parquet'\n",
    "            df.to_parquet(save_path)\n",
    "            print(f'Saved intermediate results to {save_path}')\n",
    "            return i + 1  # Return index to indicate progress\n",
    "    # Final s = f'{base_filename}_final.parquet'\n",
    "    save_path = f'{base_filename}_final.parquet'\n",
    "    df.to_parquet(save_path)\n",
    "    print(f'Final save to {save_path}')\n",
    "    del df\n",
    "    return i + 1\n",
    "\n",
    "def continue_imputation(latest_parquet):\n",
    "    \"\"\"\n",
    "    Load the latest Parquet file and continue the imputation process.\n",
    "    \n",
    "    Args:\n",
    "    latest_parquet (str): Path to the latest Parquet file.\n",
    "    numerical_categories (list): List of all columns to impute.\n",
    "    \"\"\"\n",
    "    df = cudf.read_parquet(latest_parquet)\n",
    "    categories = df.columns.to_list()\n",
    "    exclude_columns = ['ind_recommended', 'activation']\n",
    "    features_to_use = [col for col in df.columns if col not in exclude_columns]    \n",
    "    \n",
    "    last_index_processed = int(latest_parquet.split('_')[-1].replace('.parquet', ''))\n",
    "    if last_index_processed >= len(features_to_use):\n",
    "        print(\"Imputation already completed.\")\n",
    "        return\n",
    "    batch_impute_and_save(df, features_to_use, start_index=last_index_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac113590-dcd3-4cc1-9d77-57d6bbfb127e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/FYP/poon0064/.conda/envs/RunJupyter/lib/python3.10/site-packages/cuml/internals/api_decorators.py:382: UserWarning: Starting from version 23.08, the new 'copy_X' parameter defaults to 'True', ensuring a copy of X is created after passing it to fit(), preventing any changes to the input, but with increased memory usage. This represents a change in behavior from previous versions. With `copy_X=False` a copy might still be created if necessary. Explicitly set 'copy_X' to either True or False to suppress this warning.\n",
      "  return init_func(self, *args, **filtered_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start imputing...\n",
      "Model saved to impute_models/merchant_profile_03_model.pkl\n",
      "Successfully imputed values for numerical column: merchant_profile_03\n",
      "Preparing data...\n",
      "Start imputing...\n",
      "Model saved to impute_models/customer_digital_activity_01_model.pkl\n",
      "Successfully imputed values for numerical column: customer_digital_activity_01\n",
      "Preparing data...\n",
      "Start imputing...\n",
      "Model saved to impute_models/merchant_spend_10_model.pkl\n",
      "Successfully imputed values for numerical column: merchant_spend_10\n",
      "Preparing data...\n",
      "Start imputing...\n",
      "Model saved to impute_models/customer_profile_03_model.pkl\n",
      "Successfully imputed values for numerical column: customer_profile_03\n",
      "Preparing data...\n",
      "Start imputing...\n",
      "Model saved to impute_models/customer_digital_activity_02_model.pkl\n",
      "Successfully imputed values for numerical column: customer_digital_activity_02\n",
      "Preparing data...\n",
      "Start imputing...\n",
      "Model saved to impute_models/customer_profile_04_model.pkl\n",
      "Successfully imputed values for numerical column: customer_profile_04\n",
      "Preparing data...\n",
      "No imputation needed.\n",
      "Successfully imputed values for numerical column: distance_05\n",
      "Final save to imputed_df_final.parquet\n"
     ]
    }
   ],
   "source": [
    "# df = cudf.read_parquet('temp_df.parquet')\n",
    "# exclude_columns = ['ind_recommended', 'activation']\n",
    "# features_to_use = [col for col in df.columns if col not in exclude_columns]  \n",
    "# batch_impute_and_save(df, features_to_use, batch_size=6)\n",
    "\n",
    "continue_imputation('impute_data/imputed_df_54.parquet')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6931d9c-fff0-4e8b-b296-b720aaadea7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5768e06-8412-46ac-9624-31f3604f330d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
